PS D:\VS_Code_Solutions\VisualRecognition_Labs> & D:\Python\python.exe d:/VS_Code_Solutions/VisualRecognition_Labs/CNN4/gan.py
D:\Python\Lib\site-packages\torchvision\datasets\mnist.py:76: UserWarning: train_data has been renamed data
  warnings.warn("train_data has been renamed data")
[1/200]: loss_d: 1.501, loss_g: 0.504
[2/200]: loss_d: 1.416, loss_g: 0.580
[3/200]: loss_d: 1.417, loss_g: 0.605
[4/200]: loss_d: 1.409, loss_g: 0.626
[5/200]: loss_d: 1.406, loss_g: 0.638
[6/200]: loss_d: 1.400, loss_g: 0.652
[7/200]: loss_d: 1.399, loss_g: 0.658
[8/200]: loss_d: 1.397, loss_g: 0.660
[9/200]: loss_d: 1.395, loss_g: 0.664
[10/200]: loss_d: 1.395, loss_g: 0.668
[11/200]: loss_d: 1.392, loss_g: 0.673
[12/200]: loss_d: 1.394, loss_g: 0.670
[13/200]: loss_d: 1.392, loss_g: 0.675
[14/200]: loss_d: 1.391, loss_g: 0.680
[15/200]: loss_d: 1.391, loss_g: 0.674
[16/200]: loss_d: 1.391, loss_g: 0.679
[17/200]: loss_d: 1.391, loss_g: 0.682
[18/200]: loss_d: 1.391, loss_g: 0.684
[19/200]: loss_d: 1.390, loss_g: 0.684
[20/200]: loss_d: 1.390, loss_g: 0.685
[21/200]: loss_d: 1.390, loss_g: 0.685
[22/200]: loss_d: 1.390, loss_g: 0.685
[23/200]: loss_d: 1.389, loss_g: 0.686
[24/200]: loss_d: 1.389, loss_g: 0.687
[25/200]: loss_d: 1.389, loss_g: 0.686
[26/200]: loss_d: 1.389, loss_g: 0.686
[27/200]: loss_d: 1.389, loss_g: 0.688
[28/200]: loss_d: 1.389, loss_g: 0.688
[29/200]: loss_d: 1.389, loss_g: 0.686
[30/200]: loss_d: 1.389, loss_g: 0.690
[31/200]: loss_d: 1.389, loss_g: 0.688
[32/200]: loss_d: 1.389, loss_g: 0.690
[33/200]: loss_d: 1.388, loss_g: 0.685
[34/200]: loss_d: 1.390, loss_g: 0.686
[35/200]: loss_d: 1.388, loss_g: 0.689
[36/200]: loss_d: 1.389, loss_g: 0.688
[37/200]: loss_d: 1.388, loss_g: 0.689
[38/200]: loss_d: 1.388, loss_g: 0.690
[39/200]: loss_d: 1.388, loss_g: 0.690
[40/200]: loss_d: 1.388, loss_g: 0.690
[41/200]: loss_d: 1.388, loss_g: 0.691
[42/200]: loss_d: 1.388, loss_g: 0.690
[43/200]: loss_d: 1.388, loss_g: 0.692
[44/200]: loss_d: 1.388, loss_g: 0.691
[45/200]: loss_d: 1.387, loss_g: 0.691
[46/200]: loss_d: 1.387, loss_g: 0.692
[47/200]: loss_d: 1.386, loss_g: 0.687
[48/200]: loss_d: 1.388, loss_g: 0.692
[49/200]: loss_d: 1.387, loss_g: 0.691
[50/200]: loss_d: 1.388, loss_g: 0.685
[51/200]: loss_d: 1.388, loss_g: 0.693
[52/200]: loss_d: 1.387, loss_g: 0.690
[53/200]: loss_d: 1.388, loss_g: 0.690
[54/200]: loss_d: 1.388, loss_g: 0.691
[55/200]: loss_d: 1.387, loss_g: 0.693
[56/200]: loss_d: 1.388, loss_g: 0.671
[57/200]: loss_d: 1.388, loss_g: 0.682
[58/200]: loss_d: 1.388, loss_g: 0.686
[59/200]: loss_d: 1.386, loss_g: 0.689
[60/200]: loss_d: 1.389, loss_g: 0.688
[61/200]: loss_d: 1.388, loss_g: 0.690
[62/200]: loss_d: 1.387, loss_g: 0.689
[63/200]: loss_d: 1.387, loss_g: 0.690
[64/200]: loss_d: 1.388, loss_g: 0.690
[65/200]: loss_d: 1.387, loss_g: 0.689
[66/200]: loss_d: 1.387, loss_g: 0.690
[67/200]: loss_d: 1.389, loss_g: 0.690
[68/200]: loss_d: 1.388, loss_g: 0.685
[69/200]: loss_d: 1.387, loss_g: 0.694
[70/200]: loss_d: 1.387, loss_g: 0.690
[71/200]: loss_d: 1.387, loss_g: 0.693
[72/200]: loss_d: 1.387, loss_g: 0.692
