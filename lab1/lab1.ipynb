{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavloZakala/CNN/blob/main/CNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bI8YdJ6m7AH"
      },
      "source": [
        "# Задача\n",
        "\n",
        "Написати реалізацію операцій forward та backward для Conv2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CDcyNjfLlzEU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "# Helper to handle int or tuple arguments\n",
        "def to_tuple(param):\n",
        "    if isinstance(param, int):\n",
        "        return (param, param)\n",
        "    return param\n",
        "\n",
        "class MyConv2dFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, weight, bias=None, stride=1, padding=0, dilation=1):\n",
        "        \"\"\"\n",
        "        x:       (N, C_in, H, W)\n",
        "        weight:  (C_out, C_in, kH, kW)\n",
        "        bias:    (C_out,) or None\n",
        "        stride, padding, dilation: int or (h, w) tuples\n",
        "        \"\"\"\n",
        "        # Forward implementation here\n",
        "        stride_h, stride_w = to_tuple(stride)\n",
        "        pad_h, pad_w = to_tuple(padding)\n",
        "        dil_h, dil_w = to_tuple(dilation)\n",
        "\n",
        "        N, C_in, H_in, W_in = x.shape\n",
        "        C_out, _, kH, kW = weight.shape\n",
        "\n",
        "        H_out = (H_in + 2 * pad_h - dil_h * (kH - 1) - 1) // stride_h + 1\n",
        "        W_out = (W_in + 2 * pad_w - dil_w * (kW - 1) - 1) // stride_w + 1\n",
        "\n",
        "\n",
        "        x_padded = F.pad(x, (pad_w, pad_w, pad_h, pad_h), mode='constant', value=0)\n",
        "\n",
        "        output = torch.zeros((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)\n",
        "\n",
        "        # iterate over output\n",
        "        for n in range(N):\n",
        "            for cout in range(C_out):\n",
        "                for h in range(H_out):\n",
        "                    for w in range(W_out):\n",
        "                        h_start = h * stride_h\n",
        "                        w_start = w * stride_w\n",
        "                        \n",
        "                        conv_sum = 0.0\n",
        "                        for cin in range(C_in):\n",
        "                            for i in range(kH):\n",
        "                                for j in range(kW):\n",
        "                                    h_in = h_start + i * dil_h\n",
        "                                    w_in = w_start + j * dil_w\n",
        "                                    \n",
        "                                    conv_sum += x_padded[n, cin, h_in, w_in] * weight[cout, cin, i, j]\n",
        "                        \n",
        "                        output[n, cout, h, w] = conv_sum\n",
        "\n",
        "        if bias is not None:\n",
        "            output += bias.view(1, C_out, 1, 1)\n",
        "\n",
        "        ctx.save_for_backward(x, weight, bias)\n",
        "        ctx.params = (stride, padding, dilation)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        grad_output: (N, C_out, H_out, W_out)\n",
        "        returns gradients for (x, weight, bias, stride, padding, dilation)\n",
        "        \"\"\"\n",
        "        # Backward implementation here\n",
        "\n",
        "        #ctx.needs_input_grad: 0 for x, 1 for weight, 2 for bias\n",
        "        x, weight, bias = ctx.saved_tensors\n",
        "        stride, padding, dilation = ctx.params\n",
        "        \n",
        "        stride_h, stride_w = to_tuple(stride)\n",
        "        pad_h, pad_w = to_tuple(padding)\n",
        "        dil_h, dil_w = to_tuple(dilation)\n",
        "\n",
        "        N, C_in, H_in, W_in = x.shape\n",
        "        C_out, _, kH, kW = weight.shape\n",
        "        _, _, H_out, W_out = grad_output.shape\n",
        "\n",
        "        x_padded = F.pad(x, (pad_w, pad_w, pad_h, pad_h), mode='constant', value=0)\n",
        "\n",
        "\n",
        "        grad_x = None\n",
        "        grad_weight = torch.zeros_like(weight)\n",
        "        grad_bias = None\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_x_padded = torch.zeros_like(x_padded)\n",
        "        \n",
        "\n",
        "        if bias is not None and ctx.needs_input_grad[2]:\n",
        "            grad_bias = grad_output.sum(dim=(0, 2, 3))\n",
        "\n",
        "\n",
        "        for n in range(N):\n",
        "            for cout in range(C_out):\n",
        "                for h in range(H_out):\n",
        "                    for w in range(W_out):\n",
        "                        global_grad_pixel = grad_output[n, cout, h, w] # dL/dO\n",
        "                        \n",
        "                        h_start = h * stride_h\n",
        "                        w_start = w * stride_w\n",
        "\n",
        "                        for cin in range(C_in):\n",
        "                            for i in range(kH):\n",
        "                                for j in range(kW):\n",
        "                                    h_in = h_start + i * dil_h\n",
        "                                    w_in = w_start + j * dil_w\n",
        "\n",
        "                                    # dL/dW = sum(dL/dO * dO/dW), dO/dW = x\n",
        "                                    # dL/dW_pixel += global_grad_pixel * x_pixel\n",
        "                                    if ctx.needs_input_grad[1]:\n",
        "                                        grad_weight[cout, cin, i, j] += global_grad_pixel * x_padded[n, cin, h_in, w_in]\n",
        "                                    \n",
        "                                    # dL/dx = sum(dL/dO * dO/dx), dO/dx = W\n",
        "                                    # dL/dx_pixel += global_grad_pixel * weight_pixel\n",
        "                                    if ctx.needs_input_grad[0]:\n",
        "                                        grad_x_padded[n, cin, h_in, w_in] += global_grad_pixel * weight[cout, cin, i, j]\n",
        "\n",
        "        # pad removal for grad_x (N, C, H, W)\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            if pad_h > 0 or pad_w > 0:\n",
        "                origin_h_start = pad_h\n",
        "                origin_w_start = pad_w\n",
        "                origin_h_end = grad_x_padded.shape[2] - pad_h\n",
        "                origin_w_end = grad_x_padded.shape[3] - pad_w\n",
        "\n",
        "                grad_x = grad_x_padded[:, :, origin_h_start:origin_h_end, origin_w_start:origin_w_end]\n",
        "            else:\n",
        "                grad_x = grad_x_padded\n",
        "\n",
        "        # x, weight, bias, stride, padding, dilation\n",
        "        return grad_x, grad_weight, grad_bias, None, None, None\n",
        "\n",
        "\n",
        "class MyConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, bias=True):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, *kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "\n",
        "    def forward(self, x):\n",
        "        return MyConv2dFunction.apply(x, self.weight, self.bias, self.stride, self.padding, self.dilation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-vAcq7qxqRI-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 3, 3]) torch.Size([2, 2, 3, 3])\n",
            "tensor([[[[ 2.3729, -2.6914,  0.6745],\n",
            "          [ 0.8500, -1.1675,  1.9616],\n",
            "          [-3.9082,  2.1504, -0.4034]],\n",
            "\n",
            "         [[ 1.9253,  0.2542, -1.2055],\n",
            "          [ 0.0866, -1.6695,  1.0285],\n",
            "          [ 2.3610,  2.2851, -1.1022]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5413, -0.6972,  0.4987],\n",
            "          [-2.8518,  3.5412, -3.5332],\n",
            "          [-3.5641,  1.1669, -1.1376]],\n",
            "\n",
            "         [[-1.9640, -1.0002,  1.8033],\n",
            "          [-0.7915, -0.7532, -0.6293],\n",
            "          [ 3.3096,  3.2629, -0.1718]]]], device='cuda:0',\n",
            "       grad_fn=<MyConv2dFunctionBackward>)\n",
            "tensor([[[[ 2.3729, -2.6914,  0.6745],\n",
            "          [ 0.8500, -1.1675,  1.9616],\n",
            "          [-3.9082,  2.1504, -0.4034]],\n",
            "\n",
            "         [[ 1.9253,  0.2542, -1.2055],\n",
            "          [ 0.0866, -1.6695,  1.0285],\n",
            "          [ 2.3610,  2.2851, -1.1022]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5413, -0.6972,  0.4987],\n",
            "          [-2.8518,  3.5412, -3.5332],\n",
            "          [-3.5641,  1.1669, -1.1376]],\n",
            "\n",
            "         [[-1.9640, -1.0002,  1.8033],\n",
            "          [-0.7915, -0.7532, -0.6293],\n",
            "          [ 3.3096,  3.2629, -0.1718]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "Forward check: True\n",
            "w grad close: True\n",
            "b grad close: True\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "B, C, H, W = 2, 1, 3, 3\n",
        "C_out = 2\n",
        "\n",
        "x = torch.randn(B, C, H, W, device=device, requires_grad=True)\n",
        "\n",
        "myconv = MyConv2d(C, C_out, (3, 3), stride=1, padding=1, dilation=1, bias=True).to(device)\n",
        "target_conv = nn.Conv2d(C, C_out, (3, 3), stride=1, padding=1, dilation=1, bias=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    target_conv.weight.copy_(myconv.weight)\n",
        "    if myconv.bias is not None:\n",
        "        target_conv.bias.copy_(myconv.bias)\n",
        "\n",
        "# Forward check\n",
        "y_my = myconv(x)\n",
        "y_target = target_conv(x)\n",
        "print(y_my.shape, y_target.shape)\n",
        "print(y_my)\n",
        "print(y_target)\n",
        "\n",
        "print(\"Forward check:\", torch.allclose(y_my, y_target, atol=1e-6, rtol=1e-5))\n",
        "\n",
        "# Backward check\n",
        "loss_my = y_my.square().mean()\n",
        "loss_ref = y_target.square().mean()\n",
        "loss_my.backward()\n",
        "loss_ref.backward()\n",
        "\n",
        "print(\"w grad close:\", torch.allclose(myconv.weight.grad, target_conv.weight.grad, atol=1e-6, rtol=1e-5))\n",
        "if myconv.bias is not None:\n",
        "    print(\"b grad close:\", torch.allclose(myconv.bias.grad, target_conv.bias.grad, atol=1e-6, rtol=1e-5))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
